= HPC Resources for Exa-MA
Lydie Grospellier, Christophe Prud'homme 
v1.0, 2023-06-19
:doctype: book
:title-page:
//:title-page-background-image: image:media/digital-background.png[]
//:title-logo-image: image:media/logo-csmi.png[top=25%,align=center,pdfwidth=2in]
:sectnums:
:toc: left
:toclevels: 2
:icons: font
:icon-set: fab
:imagedir: 
ifdef::env-vscode[]
:imagedir: ../../images/
endif::[]

[.metadata]
{author} -- version {revnumber}, {revdate}

== Objectives

Here are the objectives for the software in the Exa-MA Project, "Methods and Algorithms for Exascale Computing":

1. Build a Global Testing Process:
   - Define a coherent structure for all demonstrators within Work Package 1 (WP1) to ensure consistency and alignment.
   - Establish a common measurement system to enable standardized evaluation and comparison of different demonstrator components.

2. Ensure Demonstrator Non-Regression:
   - Maintain a consolidated solution over time, unless there is a unanimously accepted justification for making changes.
   - Guarantee that the existing demonstrator functionalities do not regress or deteriorate during updates or modifications.

3. Ensure Non-Regression of New Developments:
   - Guarantee that new developments integrated into the demonstrator do not introduce regression or adverse effects.
   - Test and validate new developments to ensure they maintain or enhance the existing functionality and performance of the demonstrator.

4. Validate Method Applicability in a Wider Context:
   - Ensure that the developed method is not only effective on its own but also works well within a broader context of use.
   - Evaluate the method's performance and compatibility when coupled with other functionalities or integrated into a larger system.

5. Ensure Long-Term Contribution of the New Method:
   - Guarantee the sustainability and continuous improvement of the new method over time.
   - Monitor its performance, reliability, and relevance to ensure it remains valuable and beneficial in the evolving landscape of exascale computing.

6. Provide Interpretable Benefits of New Methods:
   - Establish a simple and intuitive way of interpreting and quantifying the advantages and benefits of the newly developed methods.
   - Develop metrics or measures that clearly demonstrate the positive impact and value of the new methods compared to previous approaches.

By aligning our software development and testing processes with these objectives, we can ensure the reliability, non-regression, and continuous improvement of the demonstrator while providing meaningful insights into the benefits and contributions of the new methods in the context of exascale computing.

=== Process test

Here are the process tests that we want to set up for the Exa-MA Project:

1. Non-Regression Process:
   - Objective: We want to guarantee that the result obtained remains identical to the original result, in a bit-by-bit sense, for options unaffected by proposed software evolutions.
   - Test Case: Our focus will be on a simple part of the software sources, falling into the category of elementary tests.
   - Purpose: We aim to ensure that the proposed software changes do not introduce any unintended regressions or alterations in the expected results.

2. Verification Process:
   - Objective: We aim to measure the absence of drift in consolidated solutions at a specific time (t), resulting from algorithmic optimization or improvement.
   - Test Case: The test case can be either elementary or integrated of order 1, impacting a few additional software sources.
   - Acceptance Criteria: We will define acceptable relative variation thresholds for the solution obtained.
   - Purpose: Our goal is to verify that the algorithmic changes or optimizations do not cause unintended drift or significant changes in the consolidated solutions.

3. Validation Process:
   - Objective: We want to evaluate the performance of the proposed algorithm in a real-life configuration.
   - Test Case: The test case will be representative of the objective physics of the demonstrator or a mathematical equivalent if the demonstrator is not available.
   - Integrated Validation Cases: We will develop and implement validation cases that closely mimic the expected use cases and scenarios.
   - Criteria for Measurement: We will define criteria and metrics for measuring the method's contribution and effectiveness.
   - Purpose: Our aim is to assess the algorithm's performance and validate its suitability in real-life scenarios, ensuring it contributes meaningfully to the overall objectives of the demonstrator.

These process tests cover different aspects of testing and verification, ranging from ensuring non-regression and absence of drift to evaluating the algorithm's performance in representative scenarios. By implementing these tests, we can validate the software changes, maintain stability, and measure the effectiveness of the proposed algorithms within the Exa-MA Project.

=== Demonstrator

For the Exa-MA Project, we have defined three levels of demonstrators.

Demonstrator Overview::
- Each relevant demonstrator should be listed in the demonstrator table.
- The table should include the demonstrator's name, brief description, scientific barriers that exascale could overcome, any embedded software, challenges faced by the demonstrator, and the "bottlenecks" identified (such as memory, algorithms, data management, etc.). It should also specify the associated Work Package(s) (WP) for each demonstrator.

Tests for Demonstrators::
- Each demonstrator must define its own list of tests.
- The test list should include the name of the test, the type of test (non-regression, verification, or validation), the type of computer used (CPU, GPU, etc.), and the definition of test outputs.
- Standards should be established for deviations from expected outputs.
- Test execution should provide observables indicating whether the test passed or failed.

Mini-Apps and Proxy-Apps as Demonstrators::
- Level 1 Demonstrator: A mini-app that covers one or two Exa-MA Work Packages. It focuses on specific objectives within those Work Packages.
- Level 2 Demonstrator: A mini-app that covers two or more Exa-MA Work Packages. It demonstrates cross-collaboration and integration between multiple Work Packages.
- Level 3 Demonstrator: A proxy-app that covers at least three Work Packages, potentially encompassing all Work Packages within Exa-MA. It serves as a representative workload for evaluating and optimizing the performance of high-performance computing systems.

By categorizing the demonstrators into different levels and considering Level 3 as proxy-apps, we can effectively track and evaluate their progress, ensuring they contribute to the objectives of the Exa-MA Project.

.Demonstrator Table
|===
| Demonstrator Name | Brief Description | Scientific Barriers | Embedded Software | Challenges | Bottlenecks | WP Concerned

| Level 1 Demonstrator | | | | | |
|   |   |   |   |   |   |

| Level 2 Demonstrator | | | | | |
|   |   |   |   |   |   |

| Level 3 Demonstrator | | | | | |
|   |   |   |   |   |   |
|===

For each demonstrator, we will define a list of tests with the following information:

.Demonstrator Tests
|===
| Test Name | Test Type | Computer Type | Test Outputs | Standards

| Level 1 Demonstrator | | | | 
|  | | | | 


| Level 2 Demonstrator | | | | 
|  | | | | 

| Level 3 Demonstrator | | | | 
|  | | | | 

|===

Please fill in the table with the relevant information for each demonstrator and its associated tests.

== CI/CD 

Continuous Integration/Continuous Delivery/Continuous Deployment (CI/CD/CD or simply CI/CD) strategies can be adapted and applied to high-performance computing (HPC) projects, including our project targeting exascale computing. While CI/CD is traditionally associated with software development and deployment, it can also be beneficial in managing the software and workflows associated with our HPC applications. Here are some considerations for implementing a CI/CD strategy for HPC exascale computing:

Version Control:: We will utilize a version control system (e.g., Git) to manage our HPC application's source code, scripts, and configuration files. This enables collaboration, tracks changes, and provides a history of our project.

Automated Builds:: We will implement automated build processes to compile and build our HPC application from source code. This ensures that the application is built consistently and reproducibly across different environments.

Testing and Validation:: We will develop a suite of automated tests to validate the correctness and functionality of our HPC application. This can include unit tests, integration tests, and performance tests. The tests should cover critical components and functionalities, and their execution should be automated as part of our CI/CD pipeline.

Continuous Integration:: We will set up a CI server (e.g., Jenkins, GitLab CI) that automatically builds, tests, and validates our HPC application whenever changes are pushed to the version control system. This allows us to catch errors and issues early in the development process.

Artifact Management:: We will store build artifacts, such as executables and libraries, in a central repository. This facilitates the deployment and distribution of our HPC application to different systems and environments.

Configuration Management:: We will use configuration management tools (e.g., Ansible, Puppet) to manage the configuration and deployment of our HPC application on various computing resources. This includes managing dependencies, environment variables, and system configurations.

Continuous Deployment:: We will automate the deployment of our HPC application to target systems, such as supercomputers or HPC clusters, as part of our CI/CD pipeline. This ensures that the latest version of our application is readily available for execution.

Monitoring and Logging:: We will incorporate monitoring and logging mechanisms into our HPC application to collect performance metrics, diagnose issues, and track execution progress. This helps in identifying performance bottlenecks and troubleshooting any problems that arise during runtime.

Rollback and Rollforward:: We will establish mechanisms for rolling back to a previous version of our HPC application in case of issues or failures. Additionally, we will enable the ability to roll forward to newer versions seamlessly, ensuring smooth upgrades and updates.

Collaboration and Documentation:: We will encourage collaboration within the development team by providing clear documentation on the CI/CD processes, workflows, and best practices. This helps ensure consistency across the team and facilitates knowledge sharing.

It's worth noting that the implementation details of a CI/CD strategy for HPC exascale computing may vary based on the specific requirements and constraints of our project. Considerations such as scalability, performance optimizations, and job scheduling on large-scale systems will play a significant role.

Adapting CI/CD practices to HPC can help streamline development, improve quality, and enhance the efficiency of our exascale computing project. It promotes automation, reproducibility, and collaboration, ultimately leading to more robust and reliable HPC applications.

== Containers

Containerization technologies like Docker and Singularity can play a valuable role in HPC environments, including exascale computing. They provide a way to package applications and their dependencies into portable and isolated containers, enabling consistent and reproducible execution across different computing systems. Here's how we can utilize Docker and Singularity in our HPC CI/CD strategies:

Reproducible Environments:: Containers allow us to create reproducible software environments by encapsulating the entire application stack, including the operating system, libraries, and dependencies. This ensures that our HPC applications run consistently regardless of the underlying host system.

Dependency Management:: With Docker and Singularity, we can define and manage dependencies for our HPC applications within the container. This simplifies the process of ensuring that all required software components and libraries are available and properly configured, reducing compatibility issues.

Portability:: Containers provide a portable execution environment that can be easily moved between different HPC systems, allowing our applications to run consistently across various computing resources. This is particularly useful in multi-site HPC environments or when collaborating with other researchers.

Isolation and Security:: Containers offer a level of isolation, sandboxing our HPC applications from the host system and other containers. This enhances security and prevents conflicts between different applications or libraries.

Versioning and Rollback:: Docker and Singularity enable versioning of containers, allowing us to maintain multiple versions of our HPC applications. This facilitates easy rollback to a previous version in case of issues, ensuring reproducibility and stability.

Continuous Integration with Containers:: We can incorporate containerization into our CI/CD pipeline by automating the creation, testing, and deployment of containers. This can include building containers from Dockerfiles or using Singularity build recipes. Containers can be built as part of the CI/CD process and automatically tested and deployed to the target HPC systems.

Collaboration and Sharing:: Docker Hub and Singularity Hub provide platforms for sharing and distributing containerized applications. We can leverage these platforms to share our HPC applications and their containers with collaborators or the broader community, facilitating collaboration and reproducibility.

Singularity for HPC Environments:: Singularity, in particular, is designed with HPC in mind and offers features specific to high-performance computing, such as seamless integration with resource managers (e.g., Slurm), support for GPU passthrough, and the ability to run containers as unprivileged users.

When using container technologies in HPC environments, it's important to consider certain factors, such as the performance impact of running within a container, data access and storage requirements, and specific security considerations relevant to our project and the target HPC system.

By leveraging Docker and Singularity containers, we can enhance the portability, reproducibility, and manageability of our HPC applications in the context of a CI/CD strategy.

== Mini Apps and Proxy Apps

Here are small definitions for mini apps and proxy apps:

Mini Apps:: Mini apps, short for "miniature applications," are small-scale software programs or simulations that focus on specific aspects or components of a larger application or system. They are designed to capture the essential computational patterns and performance characteristics of the larger application while being more manageable and easier to understand. Mini apps are typically used for benchmarking, performance analysis, and optimization of specific computational kernels or algorithms. They serve as representative workloads that help evaluate and optimize the performance of high-performance computing systems.

Proxy Apps:: Proxy apps, also known as "proxy applications," are software programs or simulations that mimic the behavior and computational patterns of real-world applications, particularly those used in scientific and engineering domains. They are developed with the aim of providing a lightweight representation of the computational requirements and communication patterns found in full-scale applications. Proxy apps help assess and optimize the performance

== Workflow

We propose the following workflow

.Exa-MA software development workflow
image::{imagedir}wp7-workflow.png[]

== Estimates

=== Level 1 demonstrators


.Work Package Estimates (Level 1)
|===
|Work Package | Core Hours Estimate
|Discretization | 500,000
|Model Order Reduction and ML | 1,000,000
|Solvers | 750,000
|Inverse Problems and Data Assim. | 1,500,000
|Optimization | 600,000
|Uncertainty Quantification | 900,000
| **Total** | 4,250,000
|===


